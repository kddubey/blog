{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**: Send a batch of inputs to an LLM API at once and get a batch back.\n",
    "(TODO: stream outputs back).\n",
    "\n",
    "For the [Banking 77 task](https://huggingface.co/datasets/PolyAI/banking77), increased\n",
    "throughput by 75% (1.3 -> 2.4 predictions/sec) / reduced total processing time from 218\n",
    "sec -> 125 sec. Costs latency / time-to-first-completion b/c it eats a bigger prompt.\n",
    "\n",
    "Not clear that packing is a universal benefit in terms of throughput. Pretty sure the\n",
    "trade-off is better when completions are small. Reason is that flash attention is nice\n",
    "for big prompts, but decoding is more intense. Can eval.\n",
    "\n",
    "Cost might be accuracy? At a low level, ideally, modify the attention mask to not attend\n",
    "inputs to previous inputs. Not sure if packing the extra inputs is bad. Hard to argue if\n",
    "that context is relevant or irrelevant. Hypothesize worse accuracy b/c the task is extra\n",
    "structured now and arguably irrelevant inputs. Need to run lots of experiments. For the\n",
    "Banking 77 task, when I intentionally didn't set the `seed` for subsampling, packing\n",
    "resulted in <span style=\"color:red\">-1-3%</span> accuracy (0.71 -> 0.68).\n",
    "\n",
    "**Estimated run time**: ~6 min.\n",
    "\n",
    "**Estimated dollar cost**: <$0.50.\n",
    "\n",
    "**Related work**: [paper from 2023](https://arxiv.org/abs/2301.08721). I haven't read it\n",
    "yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypeAlias\n",
    "\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import polars as pl\n",
    "from pydantic import BaseModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kdubey/Envs/base/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for PolyAI/banking77 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/banking77\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(load_dataset(\"PolyAI/banking77\", split=\"train\").to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_class_names = [\n",
    "    \"Refund_not_showing_up\",\n",
    "    \"activate_my_card\",\n",
    "    \"age_limit\",\n",
    "    \"apple_pay_or_google_pay\",\n",
    "    \"atm_support\",\n",
    "    \"automatic_top_up\",\n",
    "    \"balance_not_updated_after_bank_transfer\",\n",
    "    \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    \"beneficiary_not_allowed\",\n",
    "    \"cancel_transfer\",\n",
    "    \"card_about_to_expire\",\n",
    "    \"card_acceptance\",\n",
    "    \"card_arrival\",\n",
    "    \"card_delivery_estimate\",\n",
    "    \"card_linking\",\n",
    "    \"card_not_working\",\n",
    "    \"card_payment_fee_charged\",\n",
    "    \"card_payment_not_recognised\",\n",
    "    \"card_payment_wrong_exchange_rate\",\n",
    "    \"card_swallowed\",\n",
    "    \"cash_withdrawal_charge\",\n",
    "    \"cash_withdrawal_not_recognised\",\n",
    "    \"change_pin\",\n",
    "    \"compromised_card\",\n",
    "    \"contactless_not_working\",\n",
    "    \"country_support\",\n",
    "    \"declined_card_payment\",\n",
    "    \"declined_cash_withdrawal\",\n",
    "    \"declined_transfer\",\n",
    "    \"direct_debit_payment_not_recognised\",\n",
    "    \"disposable_card_limits\",\n",
    "    \"edit_personal_details\",\n",
    "    \"exchange_charge\",\n",
    "    \"exchange_rate\",\n",
    "    \"exchange_via_app\",\n",
    "    \"extra_charge_on_statement\",\n",
    "    \"failed_transfer\",\n",
    "    \"fiat_currency_support\",\n",
    "    \"get_disposable_virtual_card\",\n",
    "    \"get_physical_card\",\n",
    "    \"getting_spare_card\",\n",
    "    \"getting_virtual_card\",\n",
    "    \"lost_or_stolen_card\",\n",
    "    \"lost_or_stolen_phone\",\n",
    "    \"order_physical_card\",\n",
    "    \"passcode_forgotten\",\n",
    "    \"pending_card_payment\",\n",
    "    \"pending_cash_withdrawal\",\n",
    "    \"pending_top_up\",\n",
    "    \"pending_transfer\",\n",
    "    \"pin_blocked\",\n",
    "    \"receiving_money\",\n",
    "    \"request_refund\",\n",
    "    \"reverted_card_payment?\",\n",
    "    \"supported_cards_and_currencies\",\n",
    "    \"terminate_account\",\n",
    "    \"top_up_by_bank_transfer_charge\",\n",
    "    \"top_up_by_card_charge\",\n",
    "    \"top_up_by_cash_or_cheque\",\n",
    "    \"top_up_failed\",\n",
    "    \"top_up_limits\",\n",
    "    \"top_up_reverted\",\n",
    "    \"topping_up_by_card\",\n",
    "    \"transaction_charged_twice\",\n",
    "    \"transfer_fee_charged\",\n",
    "    \"transfer_into_account\",\n",
    "    \"transfer_not_received_by_recipient\",\n",
    "    \"transfer_timing\",\n",
    "    \"unable_to_verify_identity\",\n",
    "    \"verify_my_identity\",\n",
    "    \"verify_source_of_funds\",\n",
    "    \"verify_top_up\",\n",
    "    \"virtual_card_not_working\",\n",
    "    \"visa_or_mastercard\",\n",
    "    \"why_verify_identity\",\n",
    "    \"wrong_amount_of_cash_received\",\n",
    "    \"wrong_exchange_rate_for_cash_withdrawal\",\n",
    "]\n",
    "original_class_names = sorted(\n",
    "    [class_name.lower() for class_name in original_class_names]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \" \".join(class_name.split(\"_\")).capitalize() for class_name in original_class_names\n",
    "]\n",
    "class_names_str = \"\\n\".join(sorted(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.Series(\n",
    "        name=\"class_name\", values=[class_names[label_idx] for label_idx in df[\"label\"]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=300, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\\\n",
    "You are an expert at understanding bank customers support complaints and queries.\n",
    "Your job is to categorize an inputted customer query or complaint into one of the\n",
    "following categories. Also, report a confidence score from 0 to 1 for your prediction.\n",
    "\n",
    "Categories:\n",
    "\n",
    "{class_names_str}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is easy w/ structured output / constrained sampling. Just supply the list\n",
    "of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes: TypeAlias = Literal[tuple(class_names)]  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Banking77Classes(BaseModel):\n",
    "    predicted_category: Classes\n",
    "    confidence: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(max_retries=4)\n",
    "openai_kwargs = dict(model=\"gpt-4o-mini\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_message = {\"role\": \"developer\", \"content\": instruction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc0fa889e9420d9c9a416a8d6a6a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unbatched:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs_unbatched = [\n",
    "    (\n",
    "        client.beta.chat.completions.parse(\n",
    "            messages=[\n",
    "                developer_message,\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            response_format=Banking77Classes,\n",
    "            **openai_kwargs,\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.parsed\n",
    "    )\n",
    "    for text in tqdm(df_sample[\"text\"], desc=\"Unbatched\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't think you can see the progress bar in GitHub\n",
    "\n",
    "This run took 3:38, 1.31 completions/sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: don't batch via batch size. [Batch by token\n",
    "count](https://github.com/getsentry/seer/blob/108d9a7686a43b4ff062ea322f2eb74b4e3c29cc/src/seer/automation/utils.py#L269)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_sample[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably better to use XML tags or something in case the current delimiter is too\n",
    "weak or already included in the input.\n",
    "\n",
    "```\n",
    "<input_1>\n",
    "\n",
    "{input_1}\n",
    "\n",
    "</input_1>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_responses_generator = batch.complete(\n",
    "    client,\n",
    "    texts=texts,\n",
    "    instruction=instruction,\n",
    "    max_tokens=1_000,\n",
    "    response_format=Banking77Classes,\n",
    "    **openai_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a942a43f0d42969a82bb4e51a389d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completing batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs_from_batched = [\n",
    "    response\n",
    "    for responses_batch in batch_responses_generator\n",
    "    for response in responses_batch\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This run took 2 min 5 sec, or 2.4 completions/sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should instead [stream the\n",
    "outputs](https://platform.openai.com/docs/guides/structured-outputs#streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6833333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pl.Series([output.predicted_category for output in outputs_unbatched])\n",
    "    == df_sample[\"class_name\"]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pl.Series([output.predicted_category for output in outputs_from_batched])\n",
    "    == df_sample[\"class_name\"]\n",
    ").mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
