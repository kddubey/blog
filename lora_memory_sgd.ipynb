{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Description**: precursor to larger/actual experiment w/ LoRA to determine whether\n","there's savings in peak memory during training w/ SGD (not Adam) w/ LoRA vs w/o LoRA for\n","the same weights."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1850,"status":"ok","timestamp":1712552326054,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"33BjrERyC7ue"},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1712552326055,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"M5wjm8WeC7ug","outputId":"b771b274-6757-4a2e-dd92-e439b92fd306"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DEVICE"]},{"cell_type":"markdown","metadata":{},"source":["A linear model isn't enough b/c I want to show that the intermediate gradient that's\n","stored after the forward pass is the same. An MLP is enough to show that."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1712552326250,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"hIwdP-qKC7ug"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, d: int = 768) -> None:\n","        super().__init__()\n","        self.W1 = nn.Linear(d, d, device=DEVICE)\n","        self.relu = nn.ReLU()\n","        self.W2 = nn.Linear(d, d, device=DEVICE)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.W1(x)\n","        x = self.relu(x)\n","        x = self.W2(x)\n","        return x\n","\n","    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n","        return super().__call__(x)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712552326250,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"YM3DHXGJC7uh"},"outputs":[],"source":["class MLPLoRA(nn.Module):\n","    def __init__(self, d: int = 768, r: int = 2) -> None:\n","        super().__init__()\n","        self.W_frozen1 = torch.randn(size=(d, d), requires_grad=False, device=DEVICE)\n","        self.B1 = torch.randn(size=(d, r), requires_grad=True, device=DEVICE)\n","        self.A1 = torch.randn(size=(r, d), requires_grad=True, device=DEVICE)\n","\n","        self.relu = nn.ReLU()\n","\n","        self.W_frozen2 = torch.randn(size=(d, d), requires_grad=False, device=DEVICE)\n","        self.B2 = torch.randn(size=(d, r), requires_grad=True, device=DEVICE)\n","        self.A2 = torch.randn(size=(r, d), requires_grad=True, device=DEVICE)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.W_frozen1 @ x\n","        x = x + (self.B1 @ self.A1 @ x)\n","\n","        x = self.relu(x)\n","\n","        x = self.W_frozen2 @ x\n","        x = x + (self.B2 @ self.A2 @ x)\n","\n","        return x\n","\n","    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n","        return super().__call__(x)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":201,"status":"ok","timestamp":1712552326449,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"Ne2dPhOpC7ui"},"outputs":[],"source":["mlp = MLP()\n","# mlp = MLPLoRA()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1712552326784,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"I-_MKYGZC7ui"},"outputs":[],"source":["x = torch.randn(size=(768,), requires_grad=False, device=DEVICE)  # input"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1712552328730,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"H_jBMRhuDktG","outputId":"bdbcbcfd-c336-4a6b-dcf2-3c14dd08ceca"},"outputs":[{"data":{"text/plain":["4.727808"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.memory_allocated() / 1e6"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":128,"status":"ok","timestamp":1712552331709,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"U9JpTrA4C7ui"},"outputs":[],"source":["y = mlp(x)\n","loss = y.sum()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127,"status":"ok","timestamp":1712552333074,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"iCTvRYFkDEXI","outputId":"5487371c-11a6-4da7-d841-4014098bc7d8"},"outputs":[{"data":{"text/plain":["13.254144"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.memory_allocated() / 1e6"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1712552337138,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"W_cSxY96EIMw"},"outputs":[],"source":["loss.backward()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1712552338147,"user":{"displayName":"Kush Dubey","userId":"03485359534312040917"},"user_tz":420},"id":"7jOECYunEKNf","outputId":"c1062b15-36dd-429e-885c-1cbde1648160"},"outputs":[{"data":{"text/plain":["26.495488"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.memory_allocated() / 1e6"]},{"cell_type":"markdown","metadata":{},"source":["```\n","# MLP\n","4.727808\n","13.254144\n","26.495488\n","\n","# MLPLoRA\n","4.74624\n","15.634944\n","21.81376\n","```"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
