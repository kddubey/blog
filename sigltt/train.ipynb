{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPcpWU5PsO9q"
   },
   "source": [
    "**Description**: Sigmoid loss for text similarity training. Inspired by\n",
    "[SigLIP](https://arxiv.org/abs/2303.15343). Benefits are outlined in the SigLIP paper;\n",
    "it's easier to increase the batch size to get more negatives.\n",
    "\n",
    "Need to study memory more closely.\n",
    "\n",
    "**Usage**: run on a T4 GPU.\n",
    "\n",
    "Modified from this SentenceTransformers\n",
    "[script](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/matryoshka/matryoshka_nli.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZHpA1fetsVag",
    "outputId": "a7c621f3-4dc5-4e0f-9ea9-dbfd61fb4e02"
   },
   "outputs": [],
   "source": [
    "!pip install datasets --upgrade sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Tn25uJsOvmIf",
    "outputId": "2a3a4067-ce53-4b8c-ad9f-d4694bd6f73a"
   },
   "outputs": [],
   "source": [
    "!pip uninstall wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oBGfPJwnsO9r"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Any, Iterable\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    losses,\n",
    "    util,\n",
    ")\n",
    "from sentence_transformers.evaluation import (\n",
    "    EmbeddingSimilarityEvaluator,\n",
    "    SimilarityFunction,\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DWyTFKWKsO9r"
   },
   "outputs": [],
   "source": [
    "USE_CUSTOM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9RVjC8F0sO9s"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilroberta-base\"\n",
    "\n",
    "batch_size = 128\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Save path of the model\n",
    "output_dir = f\"output/sigltt_nli_{model_name.replace('/', '-')}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ki9kAIxwsO9s",
    "outputId": "19eed987-92e9-4df1-86b1-2073d19c295b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilroberta-base. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# 1. Here we define our SentenceTransformer model. If not already a Sentence Transformer model, it will automatically\n",
    "# create one with \"mean\" pooling.\n",
    "model = SentenceTransformer(model_name)\n",
    "# If we want, we can limit the maximum sequence length for the model\n",
    "# model.max_seq_length = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qzhfz9pIsO9t"
   },
   "outputs": [],
   "source": [
    "# 2. Load the AllNLI dataset: https://huggingface.co/datasets/sentence-transformers/all-nli\n",
    "train_dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"train\")\n",
    "\n",
    "# If you wish, you can limit the number of training samples\n",
    "train_dataset = train_dataset.select(range(10_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4-y3BvBuZQI"
   },
   "source": [
    "# Quick demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ASskVikquZQI"
   },
   "outputs": [],
   "source": [
    "b = 3\n",
    "_nn = 3\n",
    "m = b * (1 + _nn)  # m = len(candidates)\n",
    "\n",
    "scores = torch.randn((b, m))\n",
    "Y = torch.concat((torch.eye(b), torch.zeros((b, m - b))), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eI7_u3LuZQI",
    "outputId": "f08e1efe-7b73-4f0b-e6d0-67c01cfbf58e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5652)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "loss(scores, Y) / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSeFHZ8vuZQI",
    "outputId": "f2fbd46a-4ace-4809-98c3-cb27190057ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5652)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_sigmoid = torch.nn.LogSigmoid()\n",
    "-torch.sum(log_sigmoid((2 * Y - 1) * scores)) / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxIKRhWmuZQJ"
   },
   "source": [
    "# Loss implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z8FlKUpW-dWK"
   },
   "outputs": [],
   "source": [
    "# 3. Define our training loss\n",
    "class MultipleNegativesRankingSigmoidLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SentenceTransformer,\n",
    "        scale: float = 20.0,\n",
    "        similarity_fct=util.cos_sim,\n",
    "        bias: float = -10.0,\n",
    "    ) -> None:\n",
    "        super(MultipleNegativesRankingSigmoidLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.scale = torch.nn.Parameter(torch.tensor(scale, device=model.device))\n",
    "        self.similarity_fct = similarity_fct\n",
    "        self.bias = torch.nn.Parameter(torch.tensor(bias, device=model.device))\n",
    "        self.bce_loss = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(\n",
    "        self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # Compute the embeddings and distribute them to anchor and candidates (positive and optionally negatives)\n",
    "        embeddings = [\n",
    "            self.model(sentence_feature)[\"sentence_embedding\"]\n",
    "            for sentence_feature in sentence_features\n",
    "        ]\n",
    "        anchors = embeddings[0]  # (batch_size, embedding_dim)\n",
    "        candidates = torch.cat(\n",
    "            embeddings[1:]\n",
    "        )  # (batch_size * (1 + num_negatives), embedding_dim)\n",
    "\n",
    "        # For every anchor, we compute the similarity to all other candidates (positives and negatives),\n",
    "        # also from other anchors. This gives us a lot of in-batch negatives.\n",
    "        scores: torch.Tensor = (\n",
    "            self.similarity_fct(anchors, candidates) * self.scale\n",
    "        ) + self.bias\n",
    "        # (batch_size, batch_size * (1 + num_negatives))\n",
    "\n",
    "        # anchor[i] should be most similar to candidates[i], as that is the paired positive,\n",
    "        # so the label for anchor[i] is i\n",
    "        b = len(anchors)\n",
    "        m = len(candidates)\n",
    "        labels = torch.concat(\n",
    "            (\n",
    "                torch.eye(b, device=scores.device),\n",
    "                torch.zeros((b, m - b), device=scores.device),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "        return self.bce_loss(scores, labels) / b\n",
    "\n",
    "    def get_config_dict(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"scale\": self.scale.item(),\n",
    "            \"similarity_fct\": self.similarity_fct.__name__,\n",
    "            \"bias\": self.bias.item(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def citation(self) -> str:\n",
    "        return \"\"\"\n",
    "@inproceedings{zhai2023sigmoid,\n",
    "    title={Sigmoid loss for language image pre-training},\n",
    "    author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},\n",
    "    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
    "    pages={11975--11986},\n",
    "    year={2023}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wG3b7dDLLeRA"
   },
   "outputs": [],
   "source": [
    "# 3. Define our training loss\n",
    "class AccumulatedMultipleNegativesRankingSigmoidLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SentenceTransformer,\n",
    "        scale: float = 20.0,\n",
    "        bias: float = -10.0,\n",
    "        similarity_fct=util.cos_sim,\n",
    "        mini_batch_size: int = 32,\n",
    "        show_progress_bar: bool = False,\n",
    "    ) -> None:\n",
    "        super(AccumulatedMultipleNegativesRankingSigmoidLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.scale = torch.nn.Parameter(torch.tensor(scale, device=model.device))\n",
    "        self.bias = torch.nn.Parameter(torch.tensor(bias, device=model.device))\n",
    "        self.similarity_fct = similarity_fct\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "        self.bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _calculate_loss_mini_batch(\n",
    "        self, begin: int, anchors_mini_batch: torch.Tensor, candidates: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Loss for a mini-batch of anchors against all candidates. It's an average.\n",
    "        \"\"\"\n",
    "        mini_batch_size, _ = anchors_mini_batch.shape\n",
    "        # For every anchor, we compute the similarity to all other candidates (positives\n",
    "        # and negatives), also from other anchors. This gives us a lot of in-batch\n",
    "        # negatives.\n",
    "        scores: torch.Tensor = (\n",
    "            self.similarity_fct(anchors_mini_batch, candidates) * self.scale\n",
    "        ) + self.bias\n",
    "        # (mini_batch_size, full batch size * (1 + num negatives))\n",
    "\n",
    "        # NOTE: we could additionally batch over candidates, since the loss is just a\n",
    "        # (double) sum. (Then we'd need to backward in here.) That'd only be useful if\n",
    "        # there are millions of candidates / something wild where a mini_batch_size of 1\n",
    "        # still gives you OOMs.\n",
    "\n",
    "        # anchor[i] should be most similar to candidates[i], as that is the paired\n",
    "        # positive, so the label for anchor[i] is i. B/c we're batching anchors but not\n",
    "        # batching candidates, we need to offset the label by begin.\n",
    "        labels = torch.zeros_like(scores)\n",
    "        for i in range(mini_batch_size):\n",
    "            labels[i, begin + i] = 1.0\n",
    "        return self.bce_loss(scores, labels)\n",
    "\n",
    "    def forward(\n",
    "        self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # Compute the embeddings and distribute them to anchor and candidates (positive\n",
    "        # and optionally negatives)\n",
    "        embeddings = [\n",
    "            self.model(sentence_feature)[\"sentence_embedding\"]\n",
    "            for sentence_feature in sentence_features\n",
    "        ]\n",
    "        anchors: torch.Tensor = embeddings[0]  # (batch_size, embedding_dim)\n",
    "        candidates = torch.cat(\n",
    "            embeddings[1:]\n",
    "        )  # (batch_size * (1 + num_negatives), embedding_dim)\n",
    "        batch_size = len(anchors)\n",
    "\n",
    "        # Detach from the computation graph => don't back-propagate the gradient to the\n",
    "        # model's parameters yet. Accumulate the 2 embeddings' gradients.\n",
    "        anchors_detached = anchors.detach()\n",
    "        anchors_detached.requires_grad = True\n",
    "        candidates_detached = candidates.detach()\n",
    "        candidates_detached.requires_grad = True\n",
    "\n",
    "        # Accumulate the gradients over mini-batches of anchors, i.e., batch over rows\n",
    "        # of the similarity matrix.\n",
    "        losses: list[torch.Tensor] = []\n",
    "        for begin in tqdm.trange(\n",
    "            0,\n",
    "            batch_size,\n",
    "            self.mini_batch_size,\n",
    "            desc=\"Mini-batching\",\n",
    "            disable=not self.show_progress_bar,\n",
    "        ):\n",
    "            anchors_mini_batch = anchors_detached[\n",
    "                begin : (begin + self.mini_batch_size)\n",
    "            ]\n",
    "            mini_batch_size, _ = anchors_mini_batch.shape\n",
    "            loss_mini_batch = self._calculate_loss_mini_batch(\n",
    "                begin, anchors_mini_batch, candidates_detached\n",
    "            ) * (mini_batch_size / batch_size)  # re-scale to mimic mean over the batch\n",
    "            loss_mini_batch.backward()  # accumulate the gradient\n",
    "            losses.append(loss_mini_batch.detach())\n",
    "\n",
    "        anchors.backward(gradient=anchors_detached.grad)\n",
    "        candidates.backward(gradient=candidates_detached.grad)\n",
    "\n",
    "        loss = sum(losses).requires_grad_()\n",
    "        # That requires_grad_() lets the trainer call backward on the loss. That call\n",
    "        # does nothing b/c the loss is a sum over detached tensors. We already\n",
    "        # accumulated the gradient in the loop.\n",
    "        return loss\n",
    "\n",
    "    def get_config_dict(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"scale\": self.scale.item(),\n",
    "            \"similarity_fct\": self.similarity_fct.__name__,\n",
    "            \"bias\": self.bias.item(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def citation(self) -> str:\n",
    "        return \"\"\"\n",
    "@inproceedings{zhai2023sigmoid,\n",
    "    title={Sigmoid loss for language image pre-training},\n",
    "    author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},\n",
    "    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
    "    pages={11975--11986},\n",
    "    year={2023}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk1mUkNMuZQJ"
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCJgJZTdUha8",
    "outputId": "deec4608-c5fb-49c5-b585-89020f346df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mixed precision in bf16\n"
     ]
    }
   ],
   "source": [
    "bf16 = torch.cuda.is_bf16_supported()\n",
    "if bf16:\n",
    "    print(\"Using mixed precision in bf16\")\n",
    "else:\n",
    "    print(\"Not using mixed precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GpSAL8RKsO9u"
   },
   "outputs": [],
   "source": [
    "# 5. Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=output_dir,\n",
    "    use_mps_device=False,\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,\n",
    "    bf16=bf16,\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vy7qKIOfsO9u",
    "outputId": "c3684aa6-7a86-4fe1-8e60-8c8b1fb5d614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using **CUSTOM** Sigmoid loss\n"
     ]
    }
   ],
   "source": [
    "# 6. Create the trainer\n",
    "if USE_CUSTOM:\n",
    "    print(\"Using **CUSTOM** Sigmoid loss\")\n",
    "    train_loss = AccumulatedMultipleNegativesRankingSigmoidLoss(model)\n",
    "else:\n",
    "    print(\"Using OG MNRL\")\n",
    "    train_loss = losses.CachedMultipleNegativesRankingLoss(model)\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LqU0H7v1fbGX"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127,
     "referenced_widgets": [
      "b4b304d9296e4d998c45ada6968c2d62",
      "2c2f94ec22294ba69f5a1b6afda8c133",
      "0fef0fa2c6aa45409cbb766b64330467",
      "42863481035e4238b58aa67f6d088d27",
      "d006dc0599b14d38846efa3a2e77a082",
      "aad109c7482646c59e0b233f5c515e4e",
      "485bcf8c3c9049a6b74abaa3f391885f",
      "3d5222cab44940d58f4de5ca4369f777",
      "5da097e9547e4a829070b9af49a0405a",
      "43dd8e41d8074f699e8fa2a24f2576cf",
      "c8f3dd3b616e48fda2a5d5e3e5186b66"
     ]
    },
    "id": "MRM3MB-SQo0u",
    "outputId": "d12ba233-cbf6-40bc-bf08-83f6b17cd146"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b304d9296e4d998c45ada6968c2d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=79, training_loss=1.7152561236031447, metrics={'train_runtime': 101.6685, 'train_samples_per_second': 98.359, 'train_steps_per_second': 0.777, 'total_flos': 0.0, 'train_loss': 1.7152561236031447, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  # og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127,
     "referenced_widgets": [
      "4ef9e6be68454caebc254c9880316372",
      "e33fd9b1588748559d1cc4f8615fb613",
      "5469c4c706144be4a065dea721adb34c",
      "ad85f86b2d6547ed9c6f0d2a8c6eebfe",
      "263f93afc572462791e1d15961e5a88d",
      "40673be8ebfe427b9ff8efad36dbb213",
      "f72096d18a5c4a02aaf92bda15888df5",
      "27cc7675c3d446f0917e5af4e3d02504",
      "1039770d04354d2ca3be962134471a41",
      "5294ad1c207646a1959d8f8956a81ffa",
      "36391f72161546259c3047dc2c2c0c28"
     ]
    },
    "id": "YkNBMaOax8ce",
    "outputId": "793ce164-8ae1-41d5-89e5-7ff0149cc086"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 01:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef9e6be68454caebc254c9880316372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=79, training_loss=1.0648346913011768, metrics={'train_runtime': 86.603, 'train_samples_per_second': 115.469, 'train_steps_per_second': 0.912, 'total_flos': 0.0, 'train_loss': 1.0648346913011768, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  # custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUG7QNdo_bKu",
    "outputId": "ee6081f9-3132-4d5d-d54a-489123bbc146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(19.9979, device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(-10.0021, device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "if USE_CUSTOM:\n",
    "    print(train_loss.scale)\n",
    "    print(train_loss.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9lAllgIfeSL",
    "outputId": "5c587a23-1421-458f-8380-186bbba1efbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 1.74 GB\n",
      "Peak memory reserved: 1.97 GB\n"
     ]
    }
   ],
   "source": [
    "# og\n",
    "peak_memory_allocated = torch.cuda.max_memory_allocated()\n",
    "peak_memory_reserved = torch.cuda.max_memory_reserved()\n",
    "\n",
    "print(f\"Peak memory allocated: {peak_memory_allocated / 1024**3:.2f} GB\")\n",
    "print(f\"Peak memory reserved: {peak_memory_reserved / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHR6mlRHVUrv",
    "outputId": "11c97f2c-465c-4935-9ff2-1a4eaf3fd289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 4.45 GB\n",
      "Peak memory reserved: 5.17 GB\n"
     ]
    }
   ],
   "source": [
    "# custom\n",
    "peak_memory_allocated = torch.cuda.max_memory_allocated()\n",
    "peak_memory_reserved = torch.cuda.max_memory_reserved()\n",
    "\n",
    "print(f\"Peak memory allocated: {peak_memory_allocated / 1024**3:.2f} GB\")\n",
    "print(f\"Peak memory reserved: {peak_memory_reserved / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kuv2LbxXsO9u"
   },
   "outputs": [],
   "source": [
    "# 7. Evaluate the model performance on the STS Benchmark test dataset\n",
    "test_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"test\")\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test_dataset[\"sentence1\"],\n",
    "    sentences2=test_dataset[\"sentence2\"],\n",
    "    scores=test_dataset[\"score\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"sts-test\",\n",
    ")\n",
    "test_result = evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGiZbPTnQ71Z",
    "outputId": "255315bc-6cf5-41dd-ae1f-a82207c5ba60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sts-test_pearson_cosine': 0.7132352610537144,\n",
       " 'sts-test_spearman_cosine': 0.7167206416007149}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result  # og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdcnbOKsxvhM",
    "outputId": "e62e93bf-58ca-4837-e14e-232829237fd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sts-test_pearson_cosine': 0.7396168689438593,\n",
       " 'sts-test_spearman_cosine': 0.722019142876412}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result  # custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzMCwWvIsO9u"
   },
   "outputs": [],
   "source": [
    "# # 8. Save the trained & evaluated model locally\n",
    "# final_output_dir = f\"{output_dir}/final\"\n",
    "# model.save(final_output_dir)\n",
    "# final_output_dir"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fef0fa2c6aa45409cbb766b64330467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d5222cab44940d58f4de5ca4369f777",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5da097e9547e4a829070b9af49a0405a",
      "value": 1
     }
    },
    "1039770d04354d2ca3be962134471a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "263f93afc572462791e1d15961e5a88d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "27cc7675c3d446f0917e5af4e3d02504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c2f94ec22294ba69f5a1b6afda8c133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aad109c7482646c59e0b233f5c515e4e",
      "placeholder": "​",
      "style": "IPY_MODEL_485bcf8c3c9049a6b74abaa3f391885f",
      "value": "Computing widget examples: 100%"
     }
    },
    "36391f72161546259c3047dc2c2c0c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d5222cab44940d58f4de5ca4369f777": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40673be8ebfe427b9ff8efad36dbb213": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42863481035e4238b58aa67f6d088d27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43dd8e41d8074f699e8fa2a24f2576cf",
      "placeholder": "​",
      "style": "IPY_MODEL_c8f3dd3b616e48fda2a5d5e3e5186b66",
      "value": " 1/1 [00:00&lt;00:00,  7.75example/s]"
     }
    },
    "43dd8e41d8074f699e8fa2a24f2576cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "485bcf8c3c9049a6b74abaa3f391885f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ef9e6be68454caebc254c9880316372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e33fd9b1588748559d1cc4f8615fb613",
       "IPY_MODEL_5469c4c706144be4a065dea721adb34c",
       "IPY_MODEL_ad85f86b2d6547ed9c6f0d2a8c6eebfe"
      ],
      "layout": "IPY_MODEL_263f93afc572462791e1d15961e5a88d"
     }
    },
    "5294ad1c207646a1959d8f8956a81ffa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5469c4c706144be4a065dea721adb34c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27cc7675c3d446f0917e5af4e3d02504",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1039770d04354d2ca3be962134471a41",
      "value": 1
     }
    },
    "5da097e9547e4a829070b9af49a0405a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aad109c7482646c59e0b233f5c515e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad85f86b2d6547ed9c6f0d2a8c6eebfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5294ad1c207646a1959d8f8956a81ffa",
      "placeholder": "​",
      "style": "IPY_MODEL_36391f72161546259c3047dc2c2c0c28",
      "value": " 1/1 [00:00&lt;00:00,  9.42example/s]"
     }
    },
    "b4b304d9296e4d998c45ada6968c2d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c2f94ec22294ba69f5a1b6afda8c133",
       "IPY_MODEL_0fef0fa2c6aa45409cbb766b64330467",
       "IPY_MODEL_42863481035e4238b58aa67f6d088d27"
      ],
      "layout": "IPY_MODEL_d006dc0599b14d38846efa3a2e77a082"
     }
    },
    "c8f3dd3b616e48fda2a5d5e3e5186b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d006dc0599b14d38846efa3a2e77a082": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e33fd9b1588748559d1cc4f8615fb613": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40673be8ebfe427b9ff8efad36dbb213",
      "placeholder": "​",
      "style": "IPY_MODEL_f72096d18a5c4a02aaf92bda15888df5",
      "value": "Computing widget examples: 100%"
     }
    },
    "f72096d18a5c4a02aaf92bda15888df5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
