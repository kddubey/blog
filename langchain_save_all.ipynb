{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**: save all the stuff sent to the OpenAI API by LangChain as JSONs or in a\n",
    "dict. TODO: save outputs. Main wrinkle is handling streamed outputs.\n",
    "\n",
    "**Setup**: Install these packages\n",
    "\n",
    "```zsh\n",
    "python -m pip install langchain langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Callable, Generator, MutableMapping\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy these functions somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could instead patch the class instead of the object so that one patch globally patches\n",
    "all. But I'm not totally sure that'd work. I think I'd have to get\n",
    "`client.create.__class__` and then patch its `create` method. For now, going to stick to\n",
    "the more conservative instance patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def _monkeypatch_instance_method(obj: Any, method_name: str, new_method: Callable):\n",
    "    original_method = getattr(obj, method_name)\n",
    "    # Need to use __get__ when patching instance methods\n",
    "    # https://stackoverflow.com/a/28127947/18758987\n",
    "    try:\n",
    "        setattr(obj, method_name, new_method.__get__(obj, obj.__class__))\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(obj, method_name, original_method.__get__(obj, obj.__class__))\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _run_method_with_side_effect(\n",
    "    obj: Any, method_name: str, side_effect: Callable, yielded_obj=None\n",
    "):\n",
    "    original_method = getattr(obj, method_name)\n",
    "\n",
    "    @wraps(original_method)\n",
    "    def new_method(self, *args, **kwargs):\n",
    "        side_effect(*args, **kwargs)\n",
    "        return original_method(*args, **kwargs)\n",
    "\n",
    "    with _monkeypatch_instance_method(obj, method_name, new_method):\n",
    "        yield yielded_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_json(jsons_dir: str, *args, **kwargs):\n",
    "    # TODO: figure out what to do w/ args. For now, ignore them b/c the OpenAI client\n",
    "    # create method requires that all arguments are named\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    file_path = os.path.join(jsons_dir, f\"{current_time}.json\")\n",
    "    with open(file_path, mode=\"w\") as file:\n",
    "        json.dump(kwargs, file, indent=4)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def save_chat_create_inputs_as_jsons(client_with_create_method: Any, jsons_dir: str):\n",
    "    \"\"\"\n",
    "    In this context, save the inputs sent to some API through\n",
    "    `client_with_create_method.create` in `jsons_dir`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client_with_create_method : Any\n",
    "        some object with a `create` method, e.g.,\n",
    "        `langchain_openai.ChatOpenAI().client`. Its inputs will be saved as JSONs\n",
    "        whenever this method is called\n",
    "    jsons_dir : str\n",
    "        directory where your JSONs will get saved. The file names are timestamps\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    ::\n",
    "\n",
    "        from langchain_openai import ChatOpenAI\n",
    "\n",
    "        llm = ChatOpenAI()\n",
    "        jsons_dir = \"temp\"  # make this directory yourself\n",
    "\n",
    "        with save_chat_create_inputs_as_jsons(llm.client, jsons_dir):\n",
    "            # Note that the llm.client object is modified in this context, so any code\n",
    "            # that uses the llm will end up saving a JSON.\n",
    "            response = llm.invoke(\"how can langsmith help with testing?\")\n",
    "\n",
    "        # Then look at the json in ./jsons_dir\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    You probably only need the last JSON that's saved in `jsons_dir` b/c it'll contain\n",
    "    the chat history.\n",
    "    \"\"\"\n",
    "    side_effect = partial(_write_json, jsons_dir)\n",
    "    with _run_method_with_side_effect(client_with_create_method, \"create\", side_effect):\n",
    "        yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a non-eager way which just stores the inputs in a dict. This is better if you\n",
    "wanna control where and when to store the data. That way, you avoid JSON-writing\n",
    "overhead during the main application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_dict(\n",
    "    timestamp_to_kwargs: MutableMapping[str, dict[str, Any]], *args, **kwargs\n",
    "):\n",
    "    # TODO: figure out what to do w/ args. For now, ignore them b/c the OpenAI client\n",
    "    # create method requires that all arguments are named\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "    timestamp_to_kwargs[current_time] = kwargs\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def save_chat_create_inputs_as_dict(\n",
    "    client_with_create_method: Any,\n",
    "    existing_store: MutableMapping[str, dict[str, Any]] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    In this context, save the inputs sent to some API through\n",
    "    `client_with_create_method.create` in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client_with_create_method : Any\n",
    "        some object with a `create` method, e.g.,\n",
    "        `langchain_openai.ChatOpenAI().client`. Its inputs will be saved in a dictionary\n",
    "        whenever this method is called\n",
    "    existing_store : MutableMapping[str, dict[str, Any]], optional\n",
    "        an existing dictionary which you'd like to add to. Keys are timestamp strings.\n",
    "        By default, a new dictionary will be created\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    ::\n",
    "\n",
    "        from langchain_openai import ChatOpenAI\n",
    "\n",
    "        llm = ChatOpenAI()\n",
    "\n",
    "        with save_chat_create_inputs_as_dict(llm.client) as timestamp_to_kwargs:\n",
    "            # Note that the llm.client object is modified in this context, so any code\n",
    "            # that uses the llm will end up saving its inputs in timestamp_to_kwargs.\n",
    "            response = llm.invoke(\"how can langsmith help with testing?\")\n",
    "\n",
    "        print(timestamp_to_kwargs)\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    You probably only need the last key-value that's saved in `timestamp_to_kwargs` b/c\n",
    "    it'll contain the chat history.\n",
    "    \"\"\"\n",
    "    if existing_store is None:\n",
    "        timestamp_to_kwargs: MutableMapping[str, dict[str, Any]] = dict()\n",
    "    else:\n",
    "        timestamp_to_kwargs = existing_store\n",
    "    side_effect = partial(_update_dict, timestamp_to_kwargs)\n",
    "    with _run_method_with_side_effect(\n",
    "        client_with_create_method,\n",
    "        \"create\",\n",
    "        side_effect,\n",
    "        yielded_obj=timestamp_to_kwargs,\n",
    "    ) as timestamp_to_kwargs:\n",
    "        yield timestamp_to_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "jsons_dir = \"temp\"  # make this dir on your own pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Monkey-patching in Python can be addictive for several reasons:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Instant gratification: Monkey-patching allows you to quickly and easily modify the behavior of existing code \n",
       "without having to go through the formal process of submitting a patch or waiting for a new release. This instant \n",
       "gratification can be very satisfying and addictive.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Flexibility: Monkey-patching gives you the flexibility to make changes to code at runtime, allowing you to \n",
       "experiment and try out new ideas without having to make permanent changes to the original code.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Power and control: Monkey-patching gives you a sense of power and control over the code, allowing you to tweak \n",
       "and customize its behavior to suit your needs.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Problem-solving: Monkey-patching can be a creative and satisfying way to solve complex problems or work around \n",
       "limitations in existing code.\n",
       "\n",
       "Overall, the allure of monkey-patching in Python lies in its ability to empower developers to quickly and easily \n",
       "modify code, experiment with new ideas, and solve problems in a flexible and creative way. However, it's important \n",
       "to use monkey-patching judiciously and be mindful of the potential drawbacks, such as increased complexity and \n",
       "potential for unintended consequences.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Monkey-patching in Python can be addictive for several reasons:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. Instant gratification: Monkey-patching allows you to quickly and easily modify the behavior of existing code \n",
       "without having to go through the formal process of submitting a patch or waiting for a new release. This instant \n",
       "gratification can be very satisfying and addictive.\n",
       "\n",
       "\u001b[1;36m2\u001b[0m. Flexibility: Monkey-patching gives you the flexibility to make changes to code at runtime, allowing you to \n",
       "experiment and try out new ideas without having to make permanent changes to the original code.\n",
       "\n",
       "\u001b[1;36m3\u001b[0m. Power and control: Monkey-patching gives you a sense of power and control over the code, allowing you to tweak \n",
       "and customize its behavior to suit your needs.\n",
       "\n",
       "\u001b[1;36m4\u001b[0m. Problem-solving: Monkey-patching can be a creative and satisfying way to solve complex problems or work around \n",
       "limitations in existing code.\n",
       "\n",
       "Overall, the allure of monkey-patching in Python lies in its ability to empower developers to quickly and easily \n",
       "modify code, experiment with new ideas, and solve problems in a flexible and creative way. However, it's important \n",
       "to use monkey-patching judiciously and be mindful of the potential drawbacks, such as increased complexity and \n",
       "potential for unintended consequences.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with save_chat_create_inputs_as_jsons(llm.client, jsons_dir):\n",
    "    response = llm.invoke(\"Why am I addicted to monkey-patching in Python?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the last JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why am I addicted to monkey-patching in Python?'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'Why am I addicted to monkey-patching in Python?'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "    \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_json_file = sorted(os.listdir(jsons_dir))[-1]\n",
    "with open(os.path.join(jsons_dir, last_json_file), \"r\") as f:\n",
    "    last_inputs = json.load(f)\n",
    "print(last_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the lazy way / don't eagerly save JSONs, just add to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">It is difficult to say whether How To with John Wilson is an accurate portrayal of New York as it is a subjective \n",
       "and comedic documentary series. While the show does offer a unique and sometimes quirky perspective on life in the \n",
       "city, it may not capture the full diversity and complexity of New York. It is best to view the show as a creative \n",
       "and entertaining exploration of the city rather than a strictly accurate portrayal.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "It is difficult to say whether How To with John Wilson is an accurate portrayal of New York as it is a subjective \n",
       "and comedic documentary series. While the show does offer a unique and sometimes quirky perspective on life in the \n",
       "city, it may not capture the full diversity and complexity of New York. It is best to view the show as a creative \n",
       "and entertaining exploration of the city rather than a strictly accurate portrayal.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with save_chat_create_inputs_as_dict(llm.client) as timestamp_to_kwargs:\n",
    "    llm.invoke(\n",
    "        \"These LLM calls are independent. The next section has a more complicated demo.\"\n",
    "    )\n",
    "    response = llm.invoke(\n",
    "        \"Is How To with John Wilson an accurate portrayal of New York?\"\n",
    "    )\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in `timestamp_to_kwargs`. There were 2 calls to the LLM, so there\n",
    "should be 2 key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(timestamp_to_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-03_17-09-54-148389'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'These LLM calls are independent. The next section has a more complicated demo.'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-03_17-09-55-155838'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Is How To with John Wilson an accurate portrayal of New York?'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'2024-04-03_17-09-54-148389'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m'These LLM calls are independent. The next section has a more complicated demo.'\u001b[0m,\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'2024-04-03_17-09-55-155838'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'Is How To with John Wilson an accurate portrayal of New York?'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(timestamp_to_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify `timestamp_to_kwargs` by passing it back in to a new context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with save_chat_create_inputs_as_dict(llm.client, existing_store=timestamp_to_kwargs):\n",
    "    _ = llm.invoke(\"3. what am i doing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have 2 + 1 = 3 key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(timestamp_to_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-03_17-09-54-148389'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'These LLM calls are independent. The next section has a more complicated demo.'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-03_17-09-55-155838'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Is How To with John Wilson an accurate portrayal of New York?'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-03_17-10-01-103240'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3. what am i doing'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'2024-04-03_17-09-54-148389'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m'These LLM calls are independent. The next section has a more complicated demo.'\u001b[0m,\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'2024-04-03_17-09-55-155838'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'Is How To with John Wilson an accurate portrayal of New York?'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'2024-04-03_17-10-01-103240'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'3. what am i doing'\u001b[0m, \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "        \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.7\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(timestamp_to_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo w/ CoT and a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell is just setup. It's pulled from\n",
    "https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/07-langchain-tools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kdubey/Envs/base/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "from typing import Union\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "\n",
    "class CircumferenceTool(BaseTool):\n",
    "    name = \"Circumference calculator\"\n",
    "    description = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n",
    "\n",
    "    def _run(self, radius: Union[int, float]):\n",
    "        if isinstance(radius, str):\n",
    "            # stupid thing. I checked that this happens in the raw demo\n",
    "            radius = radius.lstrip(\"radius=: \")\n",
    "        return float(radius) * 2.0 * pi\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\"\n",
    "\n",
    "# initialize LLM (we use ChatOpenAI because we'll later define a `chat` agent)\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY, temperature=0, model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "# initialize conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=5, return_messages=True\n",
    ")\n",
    "\n",
    "\n",
    "tools = [CircumferenceTool()]\n",
    "\n",
    "# initialize agent with tools\n",
    "agent = initialize_agent(\n",
    "    agent=\"chat-conversational-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method=\"generate\",\n",
    "    memory=conversational_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running the next cell raises something like this:\n",
    "\n",
    "```python\n",
    "ValueError: could not convert string to float: 'meter / 2; radius = 4 / 2; radius = 2'\n",
    "```\n",
    "\n",
    "please run it again. I don't think it's related to the patcher b/c it happens in naked\n",
    "calls too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kdubey/Envs/base/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Circumference calculator\",\n",
      "    \"action_input\": \"radius=2\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m12.566370614359172\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The circumference of the circle with a radius of 2 is approximately 12.57 units.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jsons_dir = \"temp\"  # make this on your own\n",
    "with save_chat_create_inputs_as_jsons(llm.client, jsons_dir):\n",
    "    agent(\n",
    "        \"I have a circle with diameter 4. First calculate its radius. \"\n",
    "        \"That'll be your first observation. \"\n",
    "        \"In a new observation, calculate its circumference.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the last JSON looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helpful in answering the users original question. The tools the human can use are:\\n\\n&gt; Circumference calculator: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use this tool when you need to calculate a circumference using the radius of a circle\\n\\nRESPONSE FORMAT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following schema:\\n\\n```json\\n{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of Circumference </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calculator\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">here\\n}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code snippet of a json blob with a single action, and NOTHING else):\\n\\nI have a circle with diameter 4. First </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calculate its radius. That\\'ll be your first observation. In a new observation, calculate its circumference.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'```json\\n{\\n    \"action\": \"Circumference calculator\",\\n    \"action_input\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"radius=2\"\\n}\\n```'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"TOOL RESPONSE: \\n---------------------\\n12.566370614359172\\n\\nUSER'S </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\nObservation:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'\\n\\tObservation:'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able \u001b[0m\n",
       "\u001b[32mto assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and \u001b[0m\n",
       "\u001b[32mdiscussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on \u001b[0m\n",
       "\u001b[32mthe input it receives, allowing it to engage in natural-sounding conversations and provide responses that are \u001b[0m\n",
       "\u001b[32mcoherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities\u001b[0m\n",
       "\u001b[32mare constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to \u001b[0m\n",
       "\u001b[32mprovide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to \u001b[0m\n",
       "\u001b[32mgenerate its own text based on the input it receives, allowing it to engage in discussions and provide explanations\u001b[0m\n",
       "\u001b[32mand descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide \u001b[0m\n",
       "\u001b[32mrange of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with \u001b[0m\n",
       "\u001b[32ma specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'\u001b[0m,\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'system'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be \u001b[0m\n",
       "\u001b[32mhelpful in answering the users original question. The tools the human can use are:\\n\\n> Circumference calculator: \u001b[0m\n",
       "\u001b[32muse this tool when you need to calculate a circumference using the radius of a circle\\n\\nRESPONSE FORMAT \u001b[0m\n",
       "\u001b[32mINSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two \u001b[0m\n",
       "\u001b[32mformats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the \u001b[0m\n",
       "\u001b[32mfollowing schema:\\n\\n```json\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of Circumference \u001b[0m\n",
       "\u001b[32mcalculator\\n    \"action_input\": string \\\\\\\\ The input to the action\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n```\\n\\n**Option #2:**\\nUse this if you want\u001b[0m\n",
       "\u001b[32mto respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m\"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use \u001b[0m\n",
       "\u001b[32mhere\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input \u001b[0m\u001b[32m(\u001b[0m\u001b[32mremember to respond with a markdown\u001b[0m\n",
       "\u001b[32mcode snippet of a json blob with a single action, and NOTHING else\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\nI have a circle with diameter 4. First \u001b[0m\n",
       "\u001b[32mcalculate its radius. That\\'ll be your first observation. In a new observation, calculate its circumference.'\u001b[0m,\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'```json\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"action\": \"Circumference calculator\",\\n    \"action_input\": \u001b[0m\n",
       "\u001b[32m\"\u001b[0m\u001b[32mradius\u001b[0m\u001b[32m=\u001b[0m\u001b[32m2\"\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n```'\u001b[0m,\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"TOOL RESPONSE: \\n---------------------\\n12.566370614359172\\n\\nUSER'S \u001b[0m\n",
       "\u001b[32mINPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from\u001b[0m\n",
       "\u001b[32mthe tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! \u001b[0m\n",
       "\u001b[32mRemember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"\u001b[0m,\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-3.5-turbo'\u001b[0m,\n",
       "    \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'n'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'stop'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'\\nObservation:'\u001b[0m, \u001b[32m'\\n\\tObservation:'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_json_files = os.listdir(jsons_dir)\n",
    "_num_jsons = len(_json_files)\n",
    "\n",
    "last_json_file = sorted(_json_files)[-1]\n",
    "with open(os.path.join(jsons_dir, last_json_file), \"r\") as f:\n",
    "    last_inputs = json.load(f)\n",
    "print(last_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the context manager isn't used after it was used, verify that no extra JSONs are\n",
    "saved, i.e., we're back to using the old `create` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Circumference calculator\",\n",
      "    \"action_input\": \"2\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m12.566370614359172\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The circumference of the circle with a radius of 2 is approximately 12.57 units.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"I have a circle with diameter 4. First calculate its radius. That'll be your first observation. In a new observation, calculate its circumference.\",\n",
       " 'chat_history': [HumanMessage(content=\"I have a circle with diameter 4. First calculate its radius. That'll be your first observation. In a new observation, calculate its circumference.\"),\n",
       "  AIMessage(content='The circumference of the circle with a radius of 2 is approximately 12.57 units.')],\n",
       " 'output': 'The circumference of the circle with a radius of 2 is approximately 12.57 units.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\n",
    "    \"I have a circle with diameter 4. First calculate its radius. \"\n",
    "    \"That'll be your first observation. \"\n",
    "    \"In a new observation, calculate its circumference.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(os.listdir(jsons_dir)) == _num_jsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to also save streamed outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't love this solution b/c it ends up modifying the return type, so any previous\n",
    "`isinstance` or `issubclass` checks will return `False`. I think that's a dealbreaker,\n",
    "but maybe there are some ducktype-pilled Pythonistas out there that are fine w/ it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "from typing import Any, Callable, Generic, Iterable, Iterator, TypeVar\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_T = TypeVar(\"_T\")\n",
    "\n",
    "\n",
    "def _generator_writer(\n",
    "    generator: Iterable[_T], side_effect: Callable[[_T], Any]\n",
    ") -> Generator[_T, None, None]:\n",
    "    class _GeneratorWriter(Generic[_T]):\n",
    "        \"\"\"\n",
    "        Proxy generator which also writes to `store`. \n",
    "        \"\"\"\n",
    "\n",
    "        def __iter__(self) -> Iterator[_T]:\n",
    "            return self\n",
    "\n",
    "        def __next__(self) -> _T:\n",
    "            intermediate_output = next(generator)\n",
    "            side_effect(intermediate_output)\n",
    "            return intermediate_output\n",
    "\n",
    "        def __getattr__(self, attr: str):\n",
    "            return getattr(generator, attr)\n",
    "\n",
    "    # TODO: dynamically subclass `generator.__class__`. Doing it in the declaration or\n",
    "    # via _GeneratorWriter = type(...) messes up the __init__. Below is a failed attempt\n",
    "    # https://bugs.python.org/issue672115\n",
    "    # _GeneratorWriter.__bases__ += (generator.__class__,)\n",
    "    return _GeneratorWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_output(store: list, output: Any) -> None:\n",
    "    store.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = reversed(\"hello\")\n",
    "\n",
    "character_store = []\n",
    "side_effect = partial(store_output, character_store)\n",
    "\n",
    "generator_which_writes = _generator_writer(generator, side_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">o\n",
       "</pre>\n"
      ],
      "text/plain": [
       "o\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">l\n",
       "</pre>\n"
      ],
      "text/plain": [
       "l\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">l\n",
       "</pre>\n"
      ],
      "text/plain": [
       "l\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">e\n",
       "</pre>\n"
      ],
      "text/plain": [
       "e\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">h\n",
       "</pre>\n"
      ],
      "text/plain": [
       "h\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for char in generator_which_writes:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'l', 'l', 'e', 'h']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a real demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "token_stream = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"reply hello\"}],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "chat_completion_chunk_store = []\n",
    "generator_which_writes = _generator_writer(\n",
    "    token_stream, partial(store_output, chat_completion_chunk_store)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hello\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hello\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> How\n",
       "</pre>\n"
      ],
      "text/plain": [
       " How\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> can\n",
       "</pre>\n"
      ],
      "text/plain": [
       " can\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> I\n",
       "</pre>\n"
      ],
      "text/plain": [
       " I\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> assist\n",
       "</pre>\n"
      ],
      "text/plain": [
       " assist\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> you\n",
       "</pre>\n"
      ],
      "text/plain": [
       " you\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> today\n",
       "</pre>\n"
      ],
      "text/plain": [
       " today\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in generator_which_writes:\n",
    "    print(chunk.choices[0].delta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'!'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' How'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' can'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' I'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' assist'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' you'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' today'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionChunk</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChoiceDelta</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1712189429</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion.chunk'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b28b39ffa8'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Hello'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'!'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' How'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' can'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' I'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' assist'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' you'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m' today'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'?'\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mChatCompletionChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9A4yTfFJMr19mX0blaJy0DwhCKYXA'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mdelta\u001b[0m=\u001b[1;35mChoiceDelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1712189429\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion.chunk'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b28b39ffa8'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(chat_completion_chunk_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
